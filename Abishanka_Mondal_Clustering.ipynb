{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRL_tBEojQNE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "customers = pd.read_csv('/content/Customers.csv')\n",
        "transactions = pd.read_csv('/content/Transactions.csv')\n",
        "\n",
        "merged_data = transactions.merge(customers, on='CustomerID')\n",
        "customer_features = merged_data.groupby('CustomerID').agg({\n",
        "    'TransactionID': 'count',\n",
        "    'TotalValue': 'sum',\n",
        "    'ProductID': lambda x: len(set(x))\n",
        "}).reset_index()\n",
        "\n",
        "customer_features.columns = ['CustomerID', 'TotalTransactions', 'TotalSpending', 'UniqueProducts']\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(customer_features[['TotalTransactions', 'TotalSpending', 'UniqueProducts']])\n",
        "\n",
        "inertia = []\n",
        "for k in range(2, 11):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(features_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(2, 11), inertia, marker='o')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()\n",
        "\n",
        "optimal_k = 2\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "customer_features['Cluster'] = kmeans.fit_predict(features_scaled)\n",
        "\n",
        "db_index = davies_bouldin_score(features_scaled, customer_features['Cluster'])\n",
        "print(f'Davies-Bouldin Index: {db_index}')\n",
        "pca = PCA(n_components=2)\n",
        "features_pca = pca.fit_transform(features_scaled)\n",
        "pca_df = pd.DataFrame(data=features_pca, columns=['PCA1', 'PCA2'])\n",
        "pca_df['Cluster'] = customer_features['Cluster']\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=pca_df, x='PCA1', y='PCA2', hue='Cluster', palette='Set1', s=100)\n",
        "plt.title('Customer Segmentation Clusters')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.legend(title='Cluster')\n",
        "plt.show()\n",
        "customer_features.to_csv('Customer_Segmentation_Results.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers = pd.read_csv('/content/Customers.csv')\n",
        "transactions = pd.read_csv('/content/Transactions.csv')\n",
        "\n",
        "merged_data = transactions.merge(customers, on='CustomerID')\n",
        "customer_features = merged_data.groupby('CustomerID').agg({\n",
        "    'TransactionID': 'count',\n",
        "    'TotalValue': 'sum',\n",
        "    'ProductID': lambda x: len(set(x))\n",
        "}).reset_index()\n",
        "\n",
        "customer_features.columns = ['CustomerID', 'TotalTransactions', 'TotalSpending', 'UniqueProducts']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(customer_features[['TotalTransactions', 'TotalSpending', 'UniqueProducts']])\n",
        "for k in range(2, 11):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    labels = kmeans.fit_predict(features_scaled)\n",
        "    score = silhouette_score(features_scaled, labels)\n",
        "    print(f'Silhouette Score for k={k}: {score}')"
      ],
      "metadata": {
        "id": "XHjCwRUqjS9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for eps in [0.3, 0.5, 0.7, 1.0]:\n",
        "    dbscan = DBSCAN(eps=eps, min_samples=5)\n",
        "    labels = dbscan.fit_predict(features_scaled)\n",
        "    db_index = davies_bouldin_score(features_scaled, labels)\n",
        "    print(f'Davies-Bouldin Score for DBSCAN (eps={eps}): {db_index}')\n"
      ],
      "metadata": {
        "id": "m6foPLAFjdHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "customers = pd.read_csv('/content/Customers.csv')\n",
        "transactions = pd.read_csv('/content/Transactions.csv')\n",
        "merged_data = transactions.merge(customers, on='CustomerID')\n",
        "\n",
        "customer_features = merged_data.groupby('CustomerID').agg({\n",
        "    'TransactionID': 'count',\n",
        "    'TotalValue': 'sum',\n",
        "    'ProductID': lambda x: len(set(x))\n",
        "}).reset_index()\n",
        "\n",
        "customer_features.columns = ['CustomerID', 'TotalTransactions', 'TotalSpending', 'UniqueProducts']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(customer_features[['TotalTransactions', 'TotalSpending', 'UniqueProducts']])\n",
        "\n",
        "best_db_index = 0.282\n",
        "best_eps = 1.0\n",
        "dbscan = DBSCAN(eps=best_eps, min_samples=5)\n",
        "dbscan_labels = dbscan.fit_predict(features_scaled)\n",
        "\n",
        "customer_features['DBSCAN_Cluster'] = dbscan_labels\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "customer_features['KMeans_Cluster'] = kmeans.fit_predict(features_scaled)\n",
        "\n",
        "db_index_kmeans = 0.282\n",
        "\n",
        "silhouette_avg = silhouette_score(features_scaled, customer_features['KMeans_Cluster'])\n",
        "print(f'Silhouette Score: {silhouette_avg}')\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "features_pca = pca.fit_transform(features_scaled)\n",
        "\n",
        "pca_df = pd.DataFrame(data=features_pca, columns=['PCA1', 'PCA2'])\n",
        "\n",
        "pca_df['DBSCAN_Cluster'] = customer_features['DBSCAN_Cluster']\n",
        "pca_df['KMeans_Cluster'] = customer_features['KMeans_Cluster']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=pca_df, x='PCA1', y='PCA2', hue='DBSCAN_Cluster', palette='Set1', s=100)\n",
        "plt.title(f'DBSCAN Customer Segmentation (eps={best_eps})')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.legend(title='DBSCAN Cluster')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=pca_df, x='PCA1', y='PCA2', hue='KMeans_Cluster', palette='Set1', s=100)\n",
        "plt.title('KMeans Customer Segmentation (k=2)')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.legend(title='KMeans Cluster')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Best DBSCAN Model: eps={best_eps}, Davies-Bouldin Index={best_db_index}\")\n",
        "print(f\"KMeans Model: k=2, Davies-Bouldin Index={db_index_kmeans}\")\n"
      ],
      "metadata": {
        "id": "k5jg1Gd-jgvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dbscan_cluster_sizes = customer_features['DBSCAN_Cluster'].value_counts().sort_index()\n",
        "kmeans_cluster_sizes = customer_features['KMeans_Cluster'].value_counts().sort_index()\n",
        "print(\"DBSCAN Cluster Sizes:\")\n",
        "print(dbscan_cluster_sizes)\n",
        "\n",
        "print(\"\\nKMeans Cluster Sizes:\")\n",
        "print(kmeans_cluster_sizes)\n"
      ],
      "metadata": {
        "id": "Gv8KRhAJjjnL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}